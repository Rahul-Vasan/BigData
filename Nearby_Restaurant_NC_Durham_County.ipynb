{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f9a410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/conda/envs/bigdata/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/14 16:55:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/opt/conda/envs/bigdata/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyspark\n",
    "conf = pyspark.SparkConf()\n",
    "\n",
    "conf.set('spark.ui.proxyBase', '/user/' + os.environ['JUPYTERHUB_USER'] + '/proxy/4041')\n",
    "conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "conf.set('spark.driver.memory','8g')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "\n",
    "spark = pyspark.SQLContext.getOrCreate(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b894e8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/14 16:57:53 WARN ExtractPythonUDFFromJoinCondition: The join condition:(cast(distance_calc(geolocation_converted#141, geocode#168) as double) < 0.0167) of the join plan contains PythonUDF only, it will be moved out and the join plan will be turned to cross join.\n",
      "22/04/14 16:58:16 WARN ExtractPythonUDFFromJoinCondition: The join condition:(cast(distance_calc(geolocation_converted#141, geocode#168) as double) < 0.0167) of the join plan contains PythonUDF only, it will be moved out and the join plan will be turned to cross join.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>ID</th><th>Premise_name</th><th>count</th></tr>\n",
       "<tr><td>147244</td><td>LITTLE CAESARS #2</td><td>110</td></tr>\n",
       "<tr><td>58358</td><td>TARGET MEAT MARKET</td><td>8</td></tr>\n",
       "<tr><td>57180</td><td>TOAST</td><td>278</td></tr>\n",
       "<tr><td>56081</td><td>INTERNATIONAL DEL...</td><td>43</td></tr>\n",
       "<tr><td>57655</td><td>KROGER R 332 DELI</td><td>15</td></tr>\n",
       "<tr><td>155004</td><td>OVAL PARK GRILLE</td><td>38</td></tr>\n",
       "<tr><td>58318</td><td>TOM INSCOE WHOLES...</td><td>5</td></tr>\n",
       "<tr><td>99093</td><td>TATER BREAD CAFE</td><td>604</td></tr>\n",
       "<tr><td>57048</td><td>KFC</td><td>51</td></tr>\n",
       "<tr><td>180224</td><td>ASHANTI CATERING ...</td><td>2</td></tr>\n",
       "<tr><td>56656</td><td>CHELSEA CAFE</td><td>2</td></tr>\n",
       "<tr><td>61758</td><td>HARRIS TEETER 224...</td><td>9</td></tr>\n",
       "<tr><td>56926</td><td>STARBUCKS COFFEE ...</td><td>12</td></tr>\n",
       "<tr><td>76848</td><td>NEW JAPAN EXPRESS</td><td>32</td></tr>\n",
       "<tr><td>148160</td><td>GUSSYS</td><td>10</td></tr>\n",
       "<tr><td>56685</td><td>CHINO LATINO</td><td>188</td></tr>\n",
       "<tr><td>56171</td><td>TACO BELL</td><td>50</td></tr>\n",
       "<tr><td>80693</td><td>HOLIDAY INN EXPRE...</td><td>12</td></tr>\n",
       "<tr><td>57164</td><td>FIREHOUSE SUBS # 325</td><td>9</td></tr>\n",
       "<tr><td>170723</td><td>COCOA CINNAMON</td><td>27</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+------+--------------------+-----+\n",
       "|    ID|        Premise_name|count|\n",
       "+------+--------------------+-----+\n",
       "|147244|   LITTLE CAESARS #2|  110|\n",
       "| 58358|  TARGET MEAT MARKET|    8|\n",
       "| 57180|               TOAST|  278|\n",
       "| 56081|INTERNATIONAL DEL...|   43|\n",
       "| 57655|   KROGER R 332 DELI|   15|\n",
       "|155004|    OVAL PARK GRILLE|   38|\n",
       "| 58318|TOM INSCOE WHOLES...|    5|\n",
       "| 99093|    TATER BREAD CAFE|  604|\n",
       "| 57048|                 KFC|   51|\n",
       "|180224|ASHANTI CATERING ...|    2|\n",
       "| 56656|        CHELSEA CAFE|    2|\n",
       "| 61758|HARRIS TEETER 224...|    9|\n",
       "| 56926|STARBUCKS COFFEE ...|   12|\n",
       "| 76848|   NEW JAPAN EXPRESS|   32|\n",
       "|148160|              GUSSYS|   10|\n",
       "| 56685|        CHINO LATINO|  188|\n",
       "| 56171|           TACO BELL|   50|\n",
       "| 80693|HOLIDAY INN EXPRE...|   12|\n",
       "| 57164|FIREHOUSE SUBS # 325|    9|\n",
       "|170723|      COCOA CINNAMON|   27|\n",
       "+------+--------------------+-----+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from haversine import haversine, Unit\n",
    "restaurants = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").option(\"delimiter\",\";\").csv(\"shared/data/hw2_data/Restaurants_in_Durham_County_NC.csv\")\n",
    "restaurants = restaurants.filter((restaurants.Status==\"ACTIVE\") & (restaurants.Rpt_Area_Desc==\"Food Service\"))\n",
    "foreclosure = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").json(\"shared/data/hw2_data/durham-nc-foreclosure-2006-2016.json\")\n",
    "restaurants1 = restaurants.withColumn(\"geolocation_converted\",split(col(\"geolocation\"),\",\").cast(\"array<double>\")).select(\"ID\",\"geolocation_converted\")\n",
    "foreclosure1 = foreclosure.select(\"recordid\",\"fields.geocode\")\n",
    "def distance_calc(loc1, loc2):\n",
    "    return float(haversine(loc1, loc2, unit=Unit.DEGREES))\n",
    "dist_udf = udf(distance_calc)\n",
    "join = restaurants1.dropna().crossJoin(foreclosure1.dropna())\n",
    "join_with_distance = join.withColumn(\"distance\",dist_udf(\"geolocation_converted\",\"geocode\").cast(\"Double\"))\n",
    "total_fc_by_res = join_with_distance.filter(col(\"distance\")<0.0167).groupBy(\"ID\").count()\n",
    "final_df = restaurants.alias(\"r\").join(total_fc_by_res.alias(\"t\"),col(\"r.ID\") == col(\"t.ID\"),\"inner\")\n",
    "final_df.select(\"r.ID\",\"Premise_name\",\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc20e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bigdata]",
   "language": "python",
   "name": "conda-env-bigdata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
